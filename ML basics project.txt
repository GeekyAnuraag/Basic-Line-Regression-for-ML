%matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = (20.0,10.0)

data = pd.read_csv('headbrain.csv')
data.head()
X = data['Head Size(cm^3)'].values
Y = data['Brain Weight(grams)'].values
mean_X = np.mean(X)
mean_Y = np.mean(Y)

M = len(X)

# to calculate b1(m) and b0(c)
# I have used b1 and b0 in place of m and c respectively coz' they are part of the next-line syntaxes being used
numer = 0
denom = 0
for i in range(M):
    numer += (X[i] - mean_X) * (Y[i] - mean_Y)
    denom += (X[i] - mean_X) ** 2
b1 = numer/denom
b0 = mean_Y - (b1 * mean_X)

print(b1,b0)
#Plotting values and Regression Lines
max_X = np.max(X) + 100
min_X = np.min(X) - 100

#Calculating line values x and y

x = np.linspace(min_X, max_X, 1000)
y = b0 + b1 * x

#Plotting Line
plt.plot(x, y, color = 'black', label = 'Regression Line')

#Plotting scatter point
plt.scatter(X, Y, c = 'red', label = 'Scatter Plot')

plt.xlabel('Head Size(cm^3)')
plt.ylabel('Brain Weight(grams)')
plt.legend()
plt.show()
#For calculating R-squared
ss_t = 0
ss_r = 0
for i in range(M):
    y_pred = b0 + b1 * X[i]
    ss_t += (Y[i] - mean_Y) ** 2
    ss_r += (Y[i] - y_pred) ** 2
r2 = 1 - (ss_r/ss_t)
print("R-squared value:",r2)
    from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

#You cannot use rank-1 matrix in scikit learn
X = X.reshape((M,1))
#creating model
reg = LinearRegression()
#Fitting Training data
reg = reg.fit(X,Y)

#Y prediction
Y_pred = reg.predict(X)

#Calculating R2 score

r2_score = reg.score(X,Y)
print(r2_score)